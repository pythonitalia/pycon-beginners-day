{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Scikit-learn\n",
    "\n",
    "There are several Python libraries which provide solid implementations of a range of machine learning algorithms. One of the best known is scikit-learn, a package which provides efficient versions of a large number of common algorithms. \n",
    "\n",
    "Scikit-learn is characterized by a clean, uniform, and streamlined API, as well as by very useful and complete online documentation. A benefit of this uniformity is that once you under‚Äê stand the basic use and syntax of scikit-learn for one type of model, switching to a new model or algorithm is very straightforward.\n",
    "\n",
    "This section provides an overview of the API of scikit-learn; a solid understanding of these API elements will form the foundation for understanding the deeper practical discussion of machine learning algorithms and approaches.\n",
    "\n",
    "## Machine Learning Settings\n",
    "\n",
    "Machine learning algorithms come in two different \"flavours\":\n",
    "\n",
    "- **Supervised Learning**\n",
    "    - _Classification_\n",
    "    - _Regression_\n",
    "    \n",
    "    \n",
    "- **Unsupervised Learning**\n",
    "    - _Dimensionality Reduction_\n",
    "    - _Clustering_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/scikit-learn-cheatsheet.png\" width=\"100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Representation and Visualization of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in scikit-learn, with very few exceptions, is assumed to be stored as a\n",
    "**two-dimensional array**, of size `[n_samples, n_features]`. \n",
    "This array is usually referrred as the **feature matrix**.\n",
    "\n",
    "There is also the **label vector**, of size `n_samples`, containing the list of labels\n",
    "for each samples (_Note_: **ONLY** in the Supervised Learning settings)\n",
    "\n",
    "$$\n",
    "{\\rm feature~matrix:~~~} {\\bf X}~=~\\left[\n",
    "\\begin{matrix}\n",
    "x_{11} & x_{12} & \\cdots & x_{1D}\\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2D}\\\\\n",
    "x_{31} & x_{32} & \\cdots & x_{3D}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_{N1} & x_{N2} & \\cdots & x_{ND}\\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\rm label~vector:~~~} {\\bf y}~=~ [y_1, y_2, y_3, \\cdots y_N]\n",
    "$$\n",
    "\n",
    "Here there are $N$ samples and $D$ features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $N$ (`n_samples`):   The number of samples: each sample is an item to process (e.g. classify).\n",
    "  A sample can be a document, a picture, a sound, a video, an astronomical object,\n",
    "  a row in database or CSV file,\n",
    "  or whatever you can describe with a fixed set of quantitative traits.\n",
    "- $D$ (`n_features`):  The number of features or distinct traits that can be used to describe each\n",
    "  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\n",
    "  discrete-valued in some cases.\n",
    "\n",
    "The number of features must be fixed in advance. \n",
    "\n",
    "However it can be very high dimensional\n",
    "(e.g. millions of features) with most of them being zeros for a given sample. This is a case\n",
    "where `scipy.sparse` matrices can be useful, in that they are\n",
    "much more memory-efficient than numpy arrays.\n",
    "\n",
    "Each sample (data point) is a row in the data array, and each feature is a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Example: Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of a simple dataset, we're going to take a look at the iris data stored by scikit-learn.\n",
    "The data consists of measurements of three different species of irises.  \n",
    "\n",
    "There are three species of iris in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "    ul#flowers li {\n",
    "        display:inline !important;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<ul id=\"flowers\">\n",
    "    <li>\n",
    "        Iris Setosa\n",
    "        <img src=\"images/iris_setosa.jpg\" width=\"25%\">\n",
    "    </li>\n",
    "    <li>\n",
    "        Iris Versicolor\n",
    "        <img src=\"images/iris_versicolor.jpg\" width=\"25%\">\n",
    "    </li>\n",
    "    <li>\n",
    "        Iris Virginica\n",
    "        <img src=\"images/iris_virginica.jpg\" width=\"25%\">\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Question:\n",
    "\n",
    "**If we want to design an algorithm to recognize iris species, what might the data be?**\n",
    "\n",
    "Remember: we need a 2D array of size `[n_samples x n_features]`.\n",
    "\n",
    "- What would the `n_samples` refer to?\n",
    "\n",
    "- What might the `n_features` refer to?\n",
    "\n",
    "Remember that there must be a **fixed** number of features for each sample, and feature\n",
    "number ``i`` must be a similar kind of quantity for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1.1\n",
    "\n",
    "Load the iris dataset from `sklearn` and print out description.\n",
    "\n",
    "#### Hint: Inspect attributes of the `sklearn.datasets.base.Bunch` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1.2\n",
    "\n",
    "Save `iris` data into a numpy array `X` and print out attributes along with corresponding `targets`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1.3\n",
    "\n",
    "Plot `iris` data using a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1.3.1\n",
    "\n",
    "**Change** `x_index` **and** `y_index` **in the above script\n",
    "and find a combination of two parameters\n",
    "which maximally separate the three classes.**\n",
    "\n",
    "This exercise is a preview of **dimensionality reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1.4\n",
    "\n",
    "Loads the `digits` data and print some data extracted from the dataset.\n",
    "\n",
    "#### Hint: See `digits.data` and `digits.images`. Do you see any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised Learning: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/supervised_workflow.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2.1\n",
    "\n",
    "As classification is a supervised task, and we are interested in how well the model generalizes, we split our data into a training set,\n",
    "to built the model from, and a test-set, to evaluate how well our model performs on new data. \n",
    "The ``train_test_split`` function form the ``cross_validation`` module does that for us, by randomly splitting of 25% of the data for testing.\n",
    "\n",
    "<img src=\"images/train_test_split.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the IRIS dataset and split training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2.2 \n",
    "\n",
    "`fit` a `LogisticRegression` model to classify on training data\n",
    "\n",
    "#### Hint: Suggestions in the text !-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2.3\n",
    "\n",
    "Make Predictions on the remaining test set data\n",
    "\n",
    "#### Hint: Leverage on previsou `train-test` split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2.4\n",
    "\n",
    "Try a new Machine Learning model: `KNeighborsClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2.5\n",
    "\n",
    "Calculate the accuracy `score` on test data with the `KNeighborsClassifier`\n",
    "\n",
    "#### Hint: Clues in the text (as usual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Regression\n",
    "\n",
    "In regression we try to predict a continuous output variable. \n",
    "\n",
    "This can be most easily visualized in one dimension.\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "One of the simplest models again is a linear one, that simply tries to predict the data as lying on a line. One way to find such a line is LinearRegression (also known as ordinary least squares).\n",
    "The interface for LinearRegression is exactly the same as for the classifiers before, only that ``y`` now contains float values, instead of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3.1\n",
    "\n",
    "Generate `X` data and `y` target picking from the `sin` function plus some random noise (i.e. `np.random.uniform`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3.2\n",
    "\n",
    "Fit a linear regression model using `sklearn.linear_model.LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3.3\n",
    "\n",
    "Plot original data and predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3.4\n",
    "\n",
    "Try to think of a better model to fit. Fit and plot the data, as in previous exercises.\n",
    "\n",
    "#### Hint: `KNeighborsRegression` model, maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Unsupervised Learning\n",
    "\n",
    "<img src=\"images/unsupervised_workflow.svg\" width=\"80%\">\n",
    "\n",
    "## Clustering\n",
    "\n",
    "Clustering is the task of gathering samples into groups of similar\n",
    "samples according to some predefined similarity or dissimilarity\n",
    "measure (such as the Euclidean distance).\n",
    "In this section we will explore a basic clustering task on some synthetic and real datasets.\n",
    "\n",
    "Here are some common applications of clustering algorithms:\n",
    "\n",
    "- Compression, in a data reduction sens\n",
    "- Can be used as a preprocessing step for recommender systems\n",
    "- Similarly:\n",
    "   - grouping related web news (e.g. Google News) and web search results\n",
    "   - grouping related stock quotes for investment portfolio management\n",
    "   - building customer profiles for market analysis\n",
    "- Building a code book of prototype samples for unsupervised feature extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.1\n",
    "\n",
    "Generate some random data, organised in blobs (i.e. artifically created agglomerations of points in the space)\n",
    "\n",
    "#### Hint: Take a look at `make_blobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.2\n",
    "\n",
    "Now we will use one of the simplest clustering algorithms, K-means.\n",
    "This is an iterative algorithm which searches for three cluster\n",
    "centers such that the distance from each point to its cluster is\n",
    "minimized.\n",
    "\n",
    "\n",
    "#### Hint: See `sklearn.cluster.KMeans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
